Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 24
Rules claiming more threads will be scaled down.
Job stats:
job               count    min threads    max threads
--------------  -------  -------------  -------------
all                   1              1              1
filter_peaks          1              1              1
filter_summits        1              1              1
peak_calling          1              1              1
total                 4              1              1

Select jobs to execute...

[Tue Feb  7 17:53:41 2023]
rule peak_calling:
    input: results/mapping/test_sorted.bam, results/mapping/test_sorted.bam.bai, results/mapping/test_genome.info
    output: results/peaks/test_peaks.gappedPeak, results/peaks/test_summits.bed
    jobid: 4
    reason: Missing output files: results/peaks/test_summits.bed
    wildcards: sample=test
    resources: tmpdir=/tmp

Terminating processes on user request, this might take some time.
[Tue Feb  7 17:57:04 2023]
Error in rule peak_calling:
    jobid: 4
    input: results/mapping/test_sorted.bam, results/mapping/test_sorted.bam.bai, results/mapping/test_genome.info
    output: results/peaks/test_peaks.gappedPeak, results/peaks/test_summits.bed
    shell:
        HMMRATAC -b results/mapping/test_sorted.bam -i results/mapping/test_sorted.bam.bai -g results/mapping/test_genome.info --window 5000000
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Complete log: .snakemake/log/2023-02-07T175341.028924.snakemake.log
